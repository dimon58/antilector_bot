# Mel-Specs options
ms_sr: null # resample speech signal to 'ms_sr'
ms_fmax: 20000 # maximum considered Mel-band frequency (in Hz), set to 20k for fullband speech samples
ms_n_fft: 960 # fft size
ms_hop_length: 480 # hop length of fft windowing
ms_win_length: 960 # fft window length, will be padded with zeros to match 'ms_n_fft'
ms_n_mels: 48 # number of Mel bands
ms_seg_length: 15 # width of extracted Mel-spec segments (in bins)
ms_seg_hop_length: 3 # hop length of segments (in bins), decreasing this may improve performance but increases memory usage and runtime.
ms_channel: null # audio channel in case of stereo file (0->left, 1->right). if null, mono mix is used
ms_max_length: 1300 # spec length for training only (in bins). if samples of different duration are used in dataloader they will be padded. one segment corresponds to 40ms -> 0.04*1300=52sec max sample duration. change if you want to train on different samples


# CNN parameters
cnn_c_out_1: 16 # number of output channels of first convolutional layer
cnn_c_out_2: 32 # number of output channels of the second convolutional layer
cnn_c_out_3: 64 # number of output channels of the last four convolutional layer
cnn_kernel_size: !!python/tuple [3,3]
cnn_dropout: 0.2
cnn_fc_out_h: null # length of the CNN output feature vector, if 'null' the last fully connected layer is omitted
cnn_pool_1: [24,7] # output dimensions of first adaptive pooling ('adaptive' CNN only)
cnn_pool_2: [12,5] # output dimensions of second adaptive pooling ('adaptive' CNN only)
cnn_pool_3: [6,3] # output dimensions of third adaptive pooling ('adaptive' CNN only)

# LSTM parameters
td_lstm_h: 128 # number of LSTM hidden units
td_lstm_num_layers: 1 # LSTM depth
td_lstm_dropout: 0
td_lstm_bidirectional: true  # use bidirectional LSTM -> hidden units x 2
